{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동영상 인식 가능했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-938a561125ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "    \n",
    "detector = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture('./img2/nba_sample2.mp4')\n",
    " \n",
    "while (True):\n",
    "    ret, img = cap.read()\n",
    "    if not img is None:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    " \n",
    "    cv2.imshow('frame', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농구공 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'grabscreen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-21414465695f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgrabscreen\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgrab_screen\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'grabscreen'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    " \n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from grabscreen import grab_screen\n",
    "import cv2\n",
    " \n",
    "# This is needed to display the images.\n",
    "get_ipython().magic('matplotlib inline')\n",
    " \n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    " \n",
    " \n",
    "# ## Object detection imports\n",
    "# Here are the imports from the object detection module.\n",
    " \n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    " \n",
    " \n",
    "# # Model preparation \n",
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    " \n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    " \n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    " \n",
    "NUM_CLASSES = 90\n",
    " \n",
    " \n",
    "# ## Download Model\n",
    "# ssd_mobilenet_v1_coco_11_06_2017 이라는 모델을 다운로드하는 코드\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())\n",
    " \n",
    " \n",
    "# 하나의 그래프(노드&엣지로 이루어진 하나의 시스템)를 생성합니다\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    \n",
    "    # CKPT (저장된 가중치) 파일을 불러온 후 모델을 복원하는 코드\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    " \n",
    " \n",
    "# 라벨, 카테코리 데이터를 불러오는 코드\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    " \n",
    " \n",
    "# image vector를 numpy array로 변경하는 함수\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im.height, im_width, 3)).astype(np.uint8)\n",
    " \n",
    " \n",
    "# 위에서 복원한 모델이 있는 그래프에서\n",
    "with detection_graph.as_default():\n",
    "    # 세션을 하나 실행한다\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        while True:\n",
    "            # 아래 2줄이 Object Detection 예제코드에서 수정된 부분이다\n",
    "            # grab_screen을 사용해서 해당 윈도우를 캡처하는 코드 \n",
    "            screen = cv2.resize(grab_screen(region=(0,40,800,600)), (800,600))\n",
    "            image_np = cv2.cvtColor(screen, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "            # 이미지를 인식해서 box, score, classes를 그려주는 코드\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    " \n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    " \n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    " \n",
    "            (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n",
    " \n",
    "            # 실제로 이 코드가 box와 label을 visualize해주는 코드인듯하다\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    image_np,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    " \n",
    "            # 콘솔창을 띄운다\n",
    "            cv2.imshow('pygta-p17', image_np)\n",
    " \n",
    "            # q키를 누르면 종료한다\n",
    "            if cv2.waitKey(25) & 0xff == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement grabscreen\n",
      "ERROR: No matching distribution found for grabscreen\n"
     ]
    }
   ],
   "source": [
    "!pip install grabscreen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 인식 가능했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov4.cfg from https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov4.weights from https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yolov3_classes.txt from https://github.com/arunponnusamy/object-detection-opencv/raw/master/yolov3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[205, 348, 329, 482], [564, 99, 622, 213], [610, 51, 644, 160], [691, 306, 765, 469], [177, 111, 241, 244], [384, 173, 439, 300], [185, 207, 264, 338], [728, 67, 817, 173], [150, 38, 195, 164], [493, 84, 530, 200]] ['person', 'person', 'person', 'person', 'person', 'person', 'person', 'person', 'person', 'person'] [0.9426999688148499, 0.9157503843307495, 0.8301042914390564, 0.8298528790473938, 0.816455602645874, 0.8046301007270813, 0.7765265703201294, 0.705893337726593, 0.5886147618293762, 0.526138961315155]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "\n",
    "image_path = 'ball.PNG' # 여기에는 테스트할 이미지의 경로 및 이름을 넣어주시면 됩니다. \n",
    "im = cv2.imread(image_path) # 이미지 읽기\n",
    "# detector = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_default.xml')\n",
    "# cap = cv2.VideoCapture('test.mp4')\n",
    "\n",
    "# object detection (물체 검출)\n",
    "bbox, label, conf = cv.detect_common_objects(im)\n",
    "\n",
    "print(bbox, label, conf)\n",
    "\n",
    "im = draw_bbox(im, bbox, label, conf) \n",
    "\n",
    "\n",
    "cv2.imwrite('result.jpg', im) # 이미지 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvlib\n",
      "  Downloading cvlib-0.2.6.tar.gz (10.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\gh\\anaconda3\\lib\\site-packages (from cvlib) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gh\\anaconda3\\lib\\site-packages (from cvlib) (2.18.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\gh\\anaconda3\\lib\\site-packages (from cvlib) (5.1.0)\n",
      "Requirement already satisfied: imageio in c:\\users\\gh\\anaconda3\\lib\\site-packages (from cvlib) (2.3.0)\n",
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests->cvlib) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests->cvlib) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests->cvlib) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests->cvlib) (2020.6.20)\n",
      "Building wheels for collected packages: cvlib, imutils, progressbar\n",
      "  Building wheel for cvlib (setup.py): started\n",
      "  Building wheel for cvlib (setup.py): finished with status 'done'\n",
      "  Created wheel for cvlib: filename=cvlib-0.2.6-py3-none-any.whl size=10044633 sha256=b62a579104f831dc095e76e92fb3c44307a6338ea9352fc8f46cc322614c6b9b\n",
      "  Stored in directory: c:\\users\\gh\\appdata\\local\\pip\\cache\\wheels\\93\\ed\\05\\c69faa71b40d4a664aaa36e66a0947e6d8d1aaeb7232ea60d7\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25869 sha256=9e9f637847bf02174af357823160b9df544d948bc68968daf3ab2a8b44f5d3a8\n",
      "  Stored in directory: c:\\users\\gh\\appdata\\local\\pip\\cache\\wheels\\f5\\0c\\3a\\61b992f7aa85de40f339e6d4970d91dddb103dd0ad6c5d58f2\n",
      "  Building wheel for progressbar (setup.py): started\n",
      "  Building wheel for progressbar (setup.py): finished with status 'done'\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=10705 sha256=702900faef3a1590e98cf0bad0a5e54f8d737da2b84c796889eaa94b296646fd\n",
      "  Stored in directory: c:\\users\\gh\\appdata\\local\\pip\\cache\\wheels\\bc\\13\\93\\a9bf6b3d3966e4af014b0dbef027fdea47393faf47e990349f\n",
      "Successfully built cvlib imutils progressbar\n",
      "Installing collected packages: progressbar, imutils, cvlib\n",
      "Successfully installed cvlib-0.2.6 imutils-0.5.4 progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install cvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.4.0-cp36-cp36m-win_amd64.whl (370.6 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp36-cp36m-win_amd64.whl (2.6 MB)\n",
      "Collecting h5py~=2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-win_amd64.whl (2.4 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (51.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\gh\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.22)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp36-cp36m-win_amd64.whl\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gh\\anaconda3\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Installing collected packages: markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.3.3 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 opt-einsum-3.3.0 tensorboard-2.4.1 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\gh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\gh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\gh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\gh\\AppData\\Roaming\\Python\\Python36\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
